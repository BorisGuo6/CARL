{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden on Variation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "env_name = \"CARLDmcWalkerEnv\"\n",
    "\n",
    "database = {\n",
    "    \"CARLDmcWalkerEnv\": {\n",
    "        \"result_dir\": \"/home/benjamin/Dokumente/code/tmp/tntcomp/CARL/exp_sweep/2022-12-14/10-47-33_benchmark_train\",\n",
    "        \"folders_eval\": [\n",
    "            # \"/home/benjamin/Dokumente/code/tmp/tntcomp/CARL/multirun/2023-02-08/10-48-37\",  # old magnitudes\n",
    "            \"/home/benjamin/Dokumente/code/tmp/tntcomp/CARL/multirun/2023-02-14/14-09-02\",  # new, more magnitudes\n",
    "            \n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "outdir = f\"data/hidden_on_variations_new/{env_name}\"\n",
    "outdir = Path(outdir)\n",
    "outdir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Test Contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import carl.envs\n",
    "from experiments.common.utils.json_utils import lazy_json_dump\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from rich import print as printr\n",
    "\n",
    "env_class = eval(f\"carl.envs.{env_name}\")\n",
    "module = env_class.__module__\n",
    "default_context = eval(f\"{module}.DEFAULT_CONTEXT\")\n",
    "\n",
    "context_path = outdir / \"test_contexts.json\"\n",
    "\n",
    "magnitudes = np.arange(0.1, 2.3, 0.1)\n",
    "magnitudes = np.round(magnitudes, 1)\n",
    "# magnitudes = [0.5, 0.75, 0.9, 1., 1.1, 1.25, 1.5]\n",
    "\n",
    "mask = []\n",
    "for m in mask:\n",
    "    if m in default_context:\n",
    "        del default_context[m]\n",
    "\n",
    "context_features = list(default_context.keys())\n",
    "\n",
    "context_set = {}\n",
    "\n",
    "for cf, mag in product(context_features, magnitudes):\n",
    "    key = f\"{cf}_{mag}\"\n",
    "    default = default_context[cf]\n",
    "    if default == 0:\n",
    "        value = mag + default\n",
    "    else:\n",
    "        value = mag * default\n",
    "    context_set[key] = {cf: value}\n",
    "    for k, v in default_context.items():\n",
    "        if k != cf:\n",
    "            context_set[key][k] = v\n",
    "\n",
    "printr(f\"Created context set with {len(context_set)} contexts.\")\n",
    "# printr(context_set)\n",
    "\n",
    "lazy_json_dump(context_set, context_path)\n",
    "\n",
    "full_path = Path(context_path).resolve()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Agents & Print Eval Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from rich import print as printr\n",
    "from omegaconf import OmegaConf, ListConfig\n",
    "from experiments.evaluation.loading import fn_config\n",
    "\n",
    "# Train dir\n",
    "result_dir = database[env_name][\"result_dir\"]\n",
    "\n",
    "# Find agents\n",
    "filters = {\n",
    "    \"wandb.group\": \"hidden\",\n",
    "    \"context_sampler.context_feature_names\": [],\n",
    "    \"context_sampler.uniform_bounds_rel\": [0.9, 1.1],  # select one of the three\n",
    "}\n",
    "paths = list(Path(result_dir).glob(f\"**/{fn_config}\"))\n",
    "valid_paths = []\n",
    "for p in paths:\n",
    "    cfg = OmegaConf.load(p)\n",
    "    # printr(cfg)\n",
    "    # break\n",
    "    is_valid = True\n",
    "    for key, value in filters.items():\n",
    "        item = OmegaConf.select(cfg, key)\n",
    "        if item != value:\n",
    "            is_valid = False\n",
    "            continue\n",
    "    if is_valid:\n",
    "        valid_paths.append(str(p)[:-len(fn_config)])\n",
    "valid_paths.sort()\n",
    "printr(\"N valid agents: \", len(valid_paths))\n",
    "printr(valid_paths[0])\n",
    "\n",
    "valid_paths_str = \",\".join(valid_paths)\n",
    "\n",
    "command = f\"python experiments/evaluation/run_evaluation.py +experiments=hidden_on_variations 'hydra.launcher.timeout_min=720' 'contexts_path={full_path}' 'results_path={valid_paths_str}' -m\"\n",
    "print(command)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Eval Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import experiments.evaluation.loading\n",
    "from importlib import reload\n",
    "reload(experiments.evaluation.loading)\n",
    "\n",
    "folders_eval = database[env_name][\"folders_eval\"]\n",
    "rpc_fn = outdir / \"rpc.csv\"\n",
    "reload = True\n",
    "\n",
    "df = pd.concat([experiments.evaluation.loading.load(folder_eval=folder_eval, rpc_fn=rpc_fn, load_from_path=experiments.evaluation.loading.load_from_path_eval, reload_rpc=reload) for folder_eval in folders_eval]).reset_index(drop=True)\n",
    "\n",
    "# Convert context ids in format context_feature_name_0.3 to separate vars\n",
    "ids = df[\"context_id\"].to_list()\n",
    "for context_id in ids:\n",
    "    # Get variation\n",
    "    var = float(context_id.split(\"_\")[-1])\n",
    "    # Get contexet feature name\n",
    "    cf = context_id[:len(str(var)) + 1]\n",
    "\n",
    "from rich import print as printr\n",
    "\n",
    "n_contexts = 35\n",
    "n_cfs = 6\n",
    "n_seeds = 10\n",
    "n_reps = 10\n",
    "n_samples = n_contexts * n_cfs * n_seeds * n_reps\n",
    "printr(n_samples)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Process Eval Data\n",
    "Set proper column names, find out context feature and magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_magnitude = r\"$A$\"\n",
    "key_magnitude_train = r\"$\\Delta_{rel}$\"\n",
    "\n",
    "# Convert context ids in format context_feature_name_0.3 to separate vars\n",
    "ids = df[\"context_id\"].to_list()\n",
    "context_features = []\n",
    "magnitudes = []\n",
    "for context_id in ids:\n",
    "    # Get magnitude\n",
    "    magnitude = float(context_id.split(\"_\")[-1])\n",
    "    # Get contexet feature name\n",
    "    cf = context_id[:-(len(str(magnitude)) + 1)]\n",
    "\n",
    "    magnitudes.append(magnitude)\n",
    "    context_features.append(cf)\n",
    "df[\"context_feature\"] = context_features\n",
    "df[key_magnitude] = magnitudes\n",
    "\n",
    "for c in df.columns:\n",
    "    printr(c, df[c].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ECDF & Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plot_df = df.copy()\n",
    "# Only those trained cfs allowed\n",
    "context_feature_names = ['[]',]  #, \"['m', 'l', 'g', 'dt', 'max_speed']\"]\n",
    "plot_df = plot_df[plot_df[\"context_sampler.context_feature_names\"].isin(context_feature_names)]\n",
    "\n",
    "# Only those visibilities allowed\n",
    "visibilities = ['hidden', 'cgate_hadamard']\n",
    "plot_df = plot_df[plot_df[\"visibility\"].isin(visibilities)]\n",
    "\n",
    "# We have hidden [] three times (one for each train magnitude), use only one to be fair\n",
    "# magnitudes = [0.1]\n",
    "# plot_df = plot_df[plot_df[key_magnitude_train].isin(magnitudes)]\n",
    "\n",
    "# Filter by difficulty of test contexts\n",
    "# magnitudes = [1.1]\n",
    "# plot_df = plot_df[plot_df[key_magnitude].isin(magnitudes)]\n",
    "\n",
    "# for c in plot_df.columns:\n",
    "#     printr(c, plot_df[c].unique())\n",
    "\n",
    "print(len(plot_df))\n",
    "\n",
    "col = None  # \"$A$\"\n",
    "row = \"context_feature\"  # \"context_sampler.context_feature_names\"\n",
    "hue = key_magnitude  # \"visibility\"\n",
    "\n",
    "# ECDF\n",
    "grid = sns.FacetGrid(data=plot_df, col=col, row=row, hue=hue, legend_out=True)\n",
    "grid.map_dataframe(sns.ecdfplot, x=\"return\")\n",
    "grid.set_titles(row_template=\"train: {row_name}\", col_template=\"eval: {col_name}\")\n",
    "grid.set_titles(row_template=\"{row_name}\", col_template=\"{col_name}\")\n",
    "grid.add_legend()\n",
    "grid.savefig(outdir / \"plot_ecdf.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Histogram\n",
    "grid = sns.FacetGrid(data=plot_df, col=col, row=row, hue=hue, legend_out=True)\n",
    "grid.map_dataframe(sns.histplot, x=\"return\", element=\"step\", stat=\"frequency\")\n",
    "grid.set_titles(row_template=\"train: {row_name}\", col_template=\"eval: {col_name}\")\n",
    "grid.add_legend()\n",
    "grid.savefig(outdir / \"plot_histogram.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ax = sns.boxplot(data=df[df[key] == \"['l']\"], x=r\"$\\Delta_{rel}$\", y=\"return\", hue=\"visibility\")\n",
    "# ax.set_title(\"l\")\n",
    "# plt.show()\n",
    "\n",
    "print(len(df[df[\"visibility\"] == \"cgate_hadamard\"]))\n",
    "\n",
    "# df = df[df[\"visibility\"] == \"hidden\"]\n",
    "\n",
    "grid = sns.FacetGrid(data=df, col=r\"$\\Delta_{rel}$\", row=\"visibility\", hue=\"context_sampler.context_feature_names\", legend_out=True)\n",
    "grid.map_dataframe(sns.kdeplot, x=\"return\")\n",
    "grid.set_titles(row_template=\"{row_name}\", col_template=\"{col_name}\")\n",
    "grid.add_legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# grid = sns.FacetGrid(data=df, hue=r\"$\\Delta_{rel}$\", row=\"context_sampler.context_feature_names\", legend_out=True)\n",
    "# grid.map_dataframe(sns.kdeplot, x=\"return\")\n",
    "# grid.add_legend()\n",
    "# grid.set_titles(row_template=\"{row_name}\")\n",
    "# plt.show()\n",
    "\n",
    "key = \"context_sampler.context_feature_names\"\n",
    "grid = sns.FacetGrid(data=df[(df[key] == \"[]\") | (df[key] == \"['l']\")], col=r\"$\\Delta_{rel}$\", row=\"visibility\", hue=\"context_sampler.context_feature_names\", legend_out=True)\n",
    "grid.map_dataframe(sns.kdeplot, x=\"return\")\n",
    "grid.set_titles(row_template=\"{row_name}\", col_template=\"{col_name}\")\n",
    "grid.add_legend()\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(data=df[(df[key] == \"[]\") | (df[key] == \"['l']\")], x=r\"$\\Delta_{rel}$\", y=\"return\", hue=key)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "445f316a49a09d784fc20e9b3e621eb4aa26f31c3cfbe2b15408208fc87e667a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
