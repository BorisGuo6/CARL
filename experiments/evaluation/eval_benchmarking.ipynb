{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Benchmarking: Visualize Train Performance\n",
    "## Select Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "import pandas as pd\n",
    "import ast\n",
    "from rich import print as printr\n",
    "from rich.progress import track\n",
    "from ast import literal_eval\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "def get_eval_data_fn(outdir: str | Path, env_name: str):\n",
    "    outdir = Path(outdir)\n",
    "    eval_data_fn = outdir / f\"eval_data/{env_name}.pickle\"\n",
    "    eval_data_fn.parent.mkdir(parents=True, exist_ok=True)\n",
    "    return eval_data_fn\n",
    "\n",
    "\n",
    "def get_plot_data_fn(eval_data_fn: str | Path):\n",
    "    eval_data_fn = Path(eval_data_fn)\n",
    "    plot_data_fn = Path(eval_data_fn).parent / (Path(eval_data_fn).stem + \"_plot.csv\")\n",
    "    plot_data_fn.parent.mkdir(parents=True, exist_ok=True)\n",
    "    return plot_data_fn\n",
    "\n",
    "\n",
    "sys.path.append(\"/home/benjamin/Dokumente/code/tmp/tntcomp/CARL\")\n",
    "\n",
    "# env_name = \"CARLMountainCarEnv\"\n",
    "# env_name = \"CARLPendulumEnv\"\n",
    "# env_name = \"CARLAcrobotEnv\"\n",
    "# env_name = \"CARLDmcWalkerEnv\"\n",
    "# env_name = \"CARLDmcQuadrupedEnv\"\n",
    "env_name = \"CARLCartPoleEnv\"\n",
    "# env_name = \"CARLBipedalWalkerEnv\"\n",
    "# env_name = \"CARLMountainCarEnv\"\n",
    "# env_name = \"CARLLunarLanderEnv\"\n",
    "\n",
    "\n",
    "exp_setting = {\n",
    "    \"CARLAcrobotEnv\": {\n",
    "        \"experiment\": \"benchmarking_variation\",\n",
    "        \"algorithm\": \"c51\",\n",
    "        \"context_feature_names\": [\"link_mass_2\"],\n",
    "    },\n",
    "    \"CARLMountainCarEnv\": {\n",
    "        \"experiment\": \"benchmarking_variation\",\n",
    "        \"algorithm\": \"c51\",\n",
    "        \"context_feature_names\": [\"gravity\"],\n",
    "    },\n",
    "    \"CARLLunarLanderEnv\": {\n",
    "        \"experiment\": \"benchmarking_variation\",\n",
    "        \"algorithm\": \"c51\",\n",
    "        \"context_feature_names\": [\"GRAVITY_Y\"],\n",
    "    },\n",
    "    \"CARLPendulumEnv\": {\n",
    "        \"experiment\": \"benchmarking_variation\",\n",
    "        \"algorithm\": \"sac\",\n",
    "        \"context_feature_names\": [\"l\"],\n",
    "    },\n",
    "    \"CARLCartPoleEnv\": {\n",
    "        \"experiment\": \"benchmarking_variation\",\n",
    "        \"algorithm\": \"c51\",\n",
    "        \"context_feature_names\": [\"pole_length\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "outdir = Path(\n",
    "    f\"/home/benjamin/Dokumente/code/tmp/tntcomp/CARL/experiments/evaluation/data/benchmark/{env_name}\"\n",
    ")\n",
    "outdir.mkdir(parents=True, exist_ok=True)\n",
    "figoutdir = outdir\n",
    "figoutdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "eval_data_fn = get_eval_data_fn(outdir=outdir, env_name=env_name)\n",
    "plot_data_fn = get_plot_data_fn(eval_data_fn=eval_data_fn)\n",
    "\n",
    "config_keys = [\n",
    "    \"wandb.group\",\n",
    "    \"seed\",\n",
    "    \"context_sampler.sigma_rel\",\n",
    "    \"context_sampler.context_feature_names\",\n",
    "    \"context_sampler.uniform_bounds_rel\",\n",
    "]\n",
    "\n",
    "wandb_key_translator = {\n",
    "    \"wandb.group\": \"visibility\",\n",
    "    \"context_sampler.sigma_rel\": \"$\\sigma_{rel}$\",\n",
    "    \"context_sampler.context_feature_names\": \"C\",\n",
    "    \"train/global_step\": \"$k$\",\n",
    "    \"eval/return\": \"$R$\",\n",
    "    \"seed\": \"seed\",\n",
    "    \"context_sampler.uniform_bounds_rel\": \"$\\Delta_{rel}$\",\n",
    "}\n",
    "wkt = wandb_key_translator\n",
    "\n",
    "errorbar = \"se\"\n",
    "\n",
    "\n",
    "def get_palette_visibility(df: pd.DataFrame) -> dict:\n",
    "    key = \"wandb.group\" if \"wandb.group\" in df else wkt[\"wandb.group\"]\n",
    "    unique = df[key].unique()\n",
    "    palette = dict(\n",
    "        zip(unique, sns.color_palette(palette=\"colorblind\", n_colors=len(unique)))\n",
    "    )\n",
    "    return palette\n",
    "\n",
    "\n",
    "def load_plot_df(plot_data_fn: str, load_final: bool = False) -> pd.DataFrame:\n",
    "    plot_df = pd.read_csv(plot_data_fn)\n",
    "    plot_df.rename(columns=wandb_key_translator, inplace=True)\n",
    "    plot_df.sort_values(\n",
    "        by=[wkt[\"wandb.group\"], wkt[\"context_sampler.context_feature_names\"]],\n",
    "        inplace=True,\n",
    "    )\n",
    "    if load_final:\n",
    "        n_steps = plot_df[wkt[\"train/global_step\"]].nunique()\n",
    "        if n_steps < 1000:\n",
    "            plot_df = plot_df[\n",
    "                plot_df[wkt[\"train/global_step\"]]\n",
    "                == plot_df[wkt[\"train/global_step\"]].max()\n",
    "            ]\n",
    "        else:\n",
    "            # wandb logging messed up so we need to gather the last step per run\n",
    "            group_keys = [\n",
    "                wkt[\"wandb.group\"],\n",
    "                wkt[\"context_sampler.context_feature_names\"],\n",
    "                wkt[\"seed\"],\n",
    "                wkt[\"context_sampler.sigma_rel\"],\n",
    "                wkt[\"context_sampler.uniform_bounds_rel\"],\n",
    "            ]\n",
    "            plot_df = (\n",
    "                plot_df.groupby(group_keys)\n",
    "                .apply(\n",
    "                    lambda x: x[\n",
    "                        x[wkt[\"train/global_step\"]] == x[wkt[\"train/global_step\"]].max()\n",
    "                    ]\n",
    "                )\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "            plot_df[wkt[\"train/global_step\"]] = int(\n",
    "                round(plot_df[wkt[\"train/global_step\"]].unique().mean(), -5)\n",
    "            )\n",
    "\n",
    "        plot_df = scale(plot_df, yname=wkt[\"eval/return\"], log=False)\n",
    "        plot_df = scale(plot_df, yname=wkt[\"eval/return\"], log=True)\n",
    "    # if plot_df[wkt[\"train/global_step\"]].nunique() > 200:\n",
    "    #     plot_df = harmonize_steps(plot_df)\n",
    "\n",
    "    if wkt[\"context_sampler.uniform_bounds_rel\"] in plot_df:\n",
    "        key = wkt[\"context_sampler.uniform_bounds_rel\"]\n",
    "        replacements = {\n",
    "            \"[0.9, 1.1]\": 0.1,\n",
    "            \"[0.75, 1.25]\": 0.25,\n",
    "            \"[0.5, 1.5]\": 0.5,\n",
    "        }\n",
    "\n",
    "        for before, after in replacements.items():\n",
    "            plot_df[key][plot_df[key] == before] = after\n",
    "\n",
    "    return plot_df\n",
    "\n",
    "\n",
    "def scale(data, yname=wkt[\"eval/return\"], log: bool = True):\n",
    "    X = data[yname].to_numpy(dtype=float)\n",
    "    # log_regret = np.log(X + 1e-10)\n",
    "    # xmax = log_regret.max()\n",
    "    # xmin = log_regret.min()\n",
    "    xmax = X.max()\n",
    "    xmin = X.min()\n",
    "    # if xmin == -np.inf:\n",
    "    #     xmin = -50\n",
    "    def scaler(x):\n",
    "        # x = np.log(x + 1e-10)\n",
    "        x = (x - xmin) / (xmax - xmin)\n",
    "        if log:\n",
    "            x = np.log(x + 1e-12)\n",
    "        return x\n",
    "\n",
    "    identifier = \"_scaled\"\n",
    "    if log:\n",
    "        identifier += \"_log\"\n",
    "    data[yname + identifier] = data[yname].apply(scaler)\n",
    "    return data\n",
    "\n",
    "\n",
    "def fill_trajectory(performance_list, time_list, replace_nan=np.NaN):\n",
    "    # If the performance list contains only one list of performances:\n",
    "    # No need to fill/adjust trajectories bc there is only one.\n",
    "    if len(performance_list) < 2:\n",
    "        return np.array(performance_list), np.array(time_list).flatten()\n",
    "\n",
    "    frame_dict = OrderedDict()\n",
    "    counter = np.arange(0, len(performance_list))\n",
    "    for p, t, c in zip(performance_list, time_list, counter):\n",
    "        if len(p) != len(t):\n",
    "            raise ValueError(f\"({c}) Array length mismatch: {len(p)} != {len(t)}\")\n",
    "        frame_dict[str(c)] = pd.Series(data=p, index=t)\n",
    "\n",
    "    merged = pd.DataFrame(frame_dict)\n",
    "    merged = merged.interpolate(method=\"index\")\n",
    "\n",
    "    performance = merged.to_numpy()\n",
    "    time_ = merged.index.values\n",
    "\n",
    "    performance[np.isnan(performance)] = replace_nan\n",
    "    if not np.isfinite(performance).all():\n",
    "        raise ValueError(\n",
    "            \"\\nCould not merge lists, because \\n\"\n",
    "            \"\\t(a) one list is empty?\\n\"\n",
    "            \"\\t(b) the lists do not start with the same times and\"\n",
    "            \" replace_nan is not set?\\n\"\n",
    "            \"\\t(c) replace_nan is not set and there are non valid \"\n",
    "            \"numbers in the list\\n\"\n",
    "            \"\\t(d) any other reason.\"\n",
    "        )\n",
    "\n",
    "    return performance, time_\n",
    "\n",
    "\n",
    "def harmonize_steps(plot_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    group_keys = [wkt.get(k, k) for k in config_keys]\n",
    "    groups = plot_df.groupby(group_keys)\n",
    "    performance_list, time_list, meta_list = [], [], []\n",
    "    for group_id, group_df in groups:\n",
    "        time_list.append(group_df[wkt[\"train/global_step\"]].to_numpy())\n",
    "        performance_list.append(group_df[wkt[\"eval/return\"]].to_numpy())\n",
    "        meta_list.append(group_id)\n",
    "\n",
    "    for i in time_list:\n",
    "        i[0] = 10000\n",
    "    performance_list_transformed, time_list_transformed = fill_trajectory(\n",
    "        performance_list=performance_list, time_list=time_list\n",
    "    )\n",
    "\n",
    "    plot_df_transformed = pd.DataFrame(\n",
    "        {\n",
    "            wkt[\"train/global_step\"]: np.concatenate(\n",
    "                [time_list_transformed] * performance_list_transformed.shape[-1]\n",
    "            ),\n",
    "            wkt[\"eval/return\"]: performance_list_transformed.flatten(\"F\"),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    n_points = performance_list_transformed.shape[0]\n",
    "    tiles = np.concatenate(\n",
    "        [\n",
    "            np.tile(meta_list[i], n_points).reshape(-1, len(meta_list[i]))\n",
    "            for i in range(len(meta_list))\n",
    "        ]\n",
    "    )\n",
    "    for i, k in enumerate(group_keys):\n",
    "        plot_df_transformed[k] = tiles[:, i]\n",
    "    return plot_df_transformed\n",
    "\n",
    "\n",
    "def load_fn(run):\n",
    "    metrics = [\"eval/return\", \"train/global_step\"]\n",
    "\n",
    "    # Check metrics first. If not all available, do not append run\n",
    "    rows = []\n",
    "    for i, row in run.history(keys=metrics).iterrows():\n",
    "        if all([metric in row for metric in metrics]):\n",
    "            # df = df.append(row, ignore_index=True)\n",
    "            rows.append(row)\n",
    "        else:\n",
    "            continue\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    res_metric = df\n",
    "    res_summary = run.summary._json_dict\n",
    "    res_config = {k: v for k, v in run.config.items() if not k.startswith(\"_\")}\n",
    "    res_name = run.name\n",
    "\n",
    "    # metrics_list.append(res_metric)\n",
    "\n",
    "    # # .summary contains the output keys/values for metrics like accuracy.\n",
    "    # #  We call ._json_dict to omit large files\n",
    "    # summary_list.append(res_summary)\n",
    "\n",
    "    # # .config contains the hyperparameters.\n",
    "    # #  We remove special values that start with _.\n",
    "    # config_list.append(res_config)\n",
    "\n",
    "    # # .name is the human-readable name of the run.\n",
    "    # name_list.append(res_name)\n",
    "    return res_summary, res_config, res_name, res_metric\n",
    "\n",
    "\n",
    "def load_runs_from_wandb(\n",
    "    env_name: str, eval_data_fn: str | Path, reload: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    eval_data_fn = Path(eval_data_fn)\n",
    "    if not eval_data_fn.is_file():\n",
    "        reload = True\n",
    "\n",
    "    if reload:\n",
    "        api = wandb.Api()\n",
    "\n",
    "        # Project is specified by <entity/project-name>\n",
    "        filters = {\n",
    "            \"config.env\": env_name,\n",
    "            \"config.experiment\": exp_setting[env_name][\"experiment\"],\n",
    "            \"config.wandb.job_type\": \"train\",\n",
    "            # \"config.wandb.tags\": [\"rerun\"],\n",
    "            # \"config.context_sampler.n_samples\": 1000,\n",
    "            \"state\": \"finished\",\n",
    "            \"config.algorithm\": exp_setting[env_name][\"algorithm\"],\n",
    "        }\n",
    "        context_feature_names = exp_setting[env_name].get(\"context_feature_names\", None)\n",
    "        if context_feature_names is not None:\n",
    "            filters[\n",
    "                \"config.context_sampler.context_feature_names\"\n",
    "            ] = context_feature_names\n",
    "        printr(\"Current filters:\")\n",
    "        printr(filters)\n",
    "\n",
    "        runs = api.runs(\"tnt/carl-tmlr\", filters=filters)\n",
    "\n",
    "        summary_list, config_list, name_list, metrics_list = [], [], [], []\n",
    "\n",
    "        print(f\"Retrieving {len(runs)} runs.\")\n",
    "        for run in tqdm(runs, total=len(runs)):\n",
    "            s, c, n, m = load_fn(run)\n",
    "            summary_list.append(s)\n",
    "            config_list.append(c)\n",
    "            name_list.append(n)\n",
    "            metrics_list.append(m)\n",
    "\n",
    "        # with Pool(processes=None) as pool:\n",
    "        #     summary_list, config_list, name_list, metrics_list = pool.map(load_fn, runs)\n",
    "\n",
    "        runs_df = pd.DataFrame(\n",
    "            {\n",
    "                \"summary\": summary_list,\n",
    "                \"config\": config_list,\n",
    "                \"name\": name_list,\n",
    "                \"metrics\": metrics_list,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        runs_df.to_pickle(eval_data_fn)\n",
    "    else:\n",
    "        runs_df = pd.read_pickle(eval_data_fn)\n",
    "    return runs_df\n",
    "\n",
    "\n",
    "def convert_runs_to_plot_data(\n",
    "    runs_df: pd.DataFrame, plot_data_fn: str, config_keys: list[str]\n",
    ") -> pd.DataFrame:\n",
    "    plot_df = []\n",
    "    for idx, content in tqdm(runs_df.iterrows(), total=len(runs_df)):\n",
    "        cfg = OmegaConf.create(content[\"config\"])\n",
    "        scope = locals()\n",
    "        config_entries = {k: eval(\"cfg.\" + k, scope) for k in config_keys}\n",
    "        metrics = content[\"metrics\"]\n",
    "        n_points = len(metrics)\n",
    "        for k, v in config_entries.items():\n",
    "            metrics[k] = [v] * n_points\n",
    "        plot_df.append(metrics)\n",
    "\n",
    "    plot_df = pd.concat(plot_df)\n",
    "    plot_df.to_csv(plot_data_fn, index=False)\n",
    "    print(\"N points\", len(plot_df))\n",
    "    return plot_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Download and Convert Data\n",
    "Download runs from wandb and convert to sth plottable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "runs_df = load_runs_from_wandb(\n",
    "    env_name=env_name, eval_data_fn=eval_data_fn, reload=True\n",
    ")\n",
    "plot_df = convert_runs_to_plot_data(\n",
    "    runs_df=runs_df, plot_data_fn=plot_data_fn, config_keys=config_keys\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print unique rundirs\n",
    "runs_df = load_runs_from_wandb(\n",
    "    env_name=env_name, eval_data_fn=eval_data_fn, reload=False\n",
    ")\n",
    "rundirs = [cfg.get(\"rundir\", None) for cfg in runs_df[\"config\"]]\n",
    "rundirs = [r for r in rundirs if r is not None]\n",
    "import numpy as np\n",
    "\n",
    "np.unique(rundirs)\n",
    "# for cfg in runs_df[\"config\"]:\n",
    "#     print(cfg[\"rundir\"])\n",
    "#     break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Run Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = load_plot_df(plot_data_fn=plot_data_fn)\n",
    "plot_df\n",
    "\n",
    "experiment_design = {\n",
    "    v: list(plot_df[v].unique())\n",
    "    for k, v in wkt.items()\n",
    "    if k not in [\"train/global_step\", \"eval/return\"]\n",
    "}\n",
    "for k, v in experiment_design.items():\n",
    "    v.sort()\n",
    "\n",
    "del experiment_design[wkt[\"context_sampler.sigma_rel\"]]\n",
    "experiment_design[\"$n_{seeds}$\"] = len(experiment_design[\"seed\"])\n",
    "del experiment_design[\"seed\"]\n",
    "experiment_design[\"env\"] = env_name\n",
    "\n",
    "experiment_design = pd.Series(experiment_design)\n",
    "\n",
    "printr(experiment_design.to_latex())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Combined, Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from rliable import library as rly\n",
    "from rliable import metrics\n",
    "from rliable import plot_utils\n",
    "\n",
    "\n",
    "plot_samples = True\n",
    "identifier = \"agg\"\n",
    "kwargs = {}\n",
    "if plot_samples:\n",
    "    kwargs = dict(estimator=None, units=\"seed\", alpha=0.5)\n",
    "    identifier = \"samples\"\n",
    "\n",
    "\n",
    "fig_fn = figoutdir / f\"{env_name}_deltarel_{identifier}.pdf\"\n",
    "\n",
    "\n",
    "plot_df = load_plot_df(plot_data_fn=plot_data_fn)\n",
    "print(plot_df[wkt[\"context_sampler.context_feature_names\"]].unique())\n",
    "\n",
    "##########################################\n",
    "# CARLPendulum specific, TMLR Fig 7\n",
    "plot_df = plot_df[\n",
    "    plot_df[wkt[\"wandb.group\"]].isin([\"concat (all)\", \"concat (non-static)\", \"hidden\"])\n",
    "]\n",
    "\n",
    "if env_name == \"CARLPendulumEnv\":\n",
    "    plot_df = plot_df[plot_df[wkt[\"context_sampler.context_feature_names\"]] == \"['l']\"]\n",
    "# plot_df = plot_df[plot_df[\"seed\"] <= 10]\n",
    "###########################################\n",
    "\n",
    "palette = get_palette_visibility(plot_df)\n",
    "group_keys = [wandb_key_translator[\"context_sampler.uniform_bounds_rel\"]]\n",
    "\n",
    "\n",
    "algorithms = plot_df[\"visibility\"].unique()\n",
    "# Load ALE scores as a dictionary mapping algorithms to their human normalized\n",
    "# score matrices across all 200 million frames, each of which is of size\n",
    "# `(num_runs x num_games x 200)` where scores are recorded every million frame.\n",
    "\n",
    "seeds = list(plot_df[\"seed\"].unique())\n",
    "contexts = list(plot_df[\"C\"].unique())\n",
    "steps = list(plot_df[\"$k$\"].unique())\n",
    "visibilities = list(plot_df[\"visibility\"].unique())\n",
    "\n",
    "matrix = np.zeros((len(visibilities), len(seeds), len(contexts), len(steps)))\n",
    "\n",
    "for gid, gdf in plot_df.groupby([\"visibility\", \"seed\", \"C\", \"$k$\"]):\n",
    "    R = gdf[\"$R$\"]\n",
    "    v_i = visibilities.index(gid[0])\n",
    "    s_i = seeds.index(gid[1])\n",
    "    c_i = contexts.index(gid[2])\n",
    "    st_i = steps.index(gid[3])\n",
    "    matrix[v_i, s_i, c_i, st_i] = R\n",
    "\n",
    "score_dict = {v: matrix[i] for i, v in enumerate(visibilities)}\n",
    "\n",
    "\n",
    "iqm = lambda scores: np.array(\n",
    "    [metrics.aggregate_mean(scores[..., frame]) for frame in range(scores.shape[-1])]\n",
    ")\n",
    "iqm_scores, iqm_cis = rly.get_interval_estimates(score_dict, iqm, reps=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=1.1)\n",
    "\n",
    "ax = plot_utils.plot_sample_efficiency_curve(\n",
    "    steps,\n",
    "    iqm_scores,\n",
    "    iqm_cis,\n",
    "    algorithms=algorithms,\n",
    "    xlabel=r\"Steps\",\n",
    "    ylabel=\"Return\",\n",
    "    figsize=(6, 4),\n",
    ")\n",
    "ax.legend(prop=dict(size=16))\n",
    "\n",
    "\n",
    "fig = ax.get_figure()\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "fig_fn2 = figoutdir / f\"{env_name}_training_curve.pdf\"\n",
    "fig.savefig(fig_fn2, bbox_inches=\"tight\", dpi=300)\n",
    "print(fig_fn2)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=2)\n",
    "\n",
    "fig = plt.figure(figsize=(6, 4), dpi=300)\n",
    "ax = fig.add_subplot(111)\n",
    "ax = sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=plot_df,\n",
    "    x=wkt[\"train/global_step\"],\n",
    "    y=wkt[\"eval/return\"],\n",
    "    hue=wkt[\"wandb.group\"],\n",
    "    palette=palette,\n",
    "    errorbar=\"ci\",\n",
    "    lw=2,\n",
    "    **kwargs,\n",
    ")\n",
    "# xticks = np.linspace(0, round(plot_df[wkt[\"train/global_step\"]].max(), -5), 5) # TODO\n",
    "# grid.set(xticks=xticks)\n",
    "ax.set_xlabel(\"Step\")\n",
    "ax.set_ylabel(\"Return\")\n",
    "fig.savefig(fig_fn, bbox_inches=\"tight\", dpi=300)\n",
    "print(fig_fn)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "assert exp_setting[env_name][\"algorithm\"] == \"c51\"\n",
    "\n",
    "fig_fn = figoutdir / f\"{env_name}_training_curve.pdf\"\n",
    "\n",
    "\n",
    "plot_df = load_plot_df(plot_data_fn=plot_data_fn)\n",
    "print(plot_df[wkt[\"context_sampler.context_feature_names\"]].unique())\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=2)\n",
    "\n",
    "palette = get_palette_visibility(plot_df)\n",
    "\n",
    "\n",
    "def interpolate_steps(\n",
    "    df: pd.DataFrame,\n",
    "    xlim: tuple[int, int],\n",
    "    method: str = \"linear\",\n",
    "    n_points: int = 20,\n",
    "    x_key: str = wkt[\"train/global_step\"],\n",
    "    y_key: str = wkt[\"eval/return\"],\n",
    ") -> pd.DataFrame:\n",
    "    x = df[x_key]\n",
    "    y = df[y_key]\n",
    "    # xlim = (x.min(), x.max())\n",
    "    x_ip = np.linspace(*xlim, n_points)\n",
    "\n",
    "    y_ip = interp1d(x, y, kind=method, bounds_error=False, fill_value=\"extrapolate\")(\n",
    "        x_ip\n",
    "    )\n",
    "\n",
    "    new_df = pd.DataFrame()\n",
    "\n",
    "    # new_df[\"step_interpolated\"] = x_ip\n",
    "    # new_df[\"return_interpolated\"] = y_ip\n",
    "\n",
    "    new_df[x_key] = x_ip\n",
    "    new_df[y_key] = y_ip\n",
    "\n",
    "    return new_df\n",
    "\n",
    "\n",
    "x_key = wkt[\"train/global_step\"]\n",
    "y_key = wkt[\"eval/return\"]\n",
    "\n",
    "xlim = (plot_df[x_key].min(), plot_df[x_key].max())\n",
    "\n",
    "# x_key = \"step_interpolated\"\n",
    "# y_key = \"return_interpolated\"\n",
    "\n",
    "\n",
    "df = plot_df.groupby(by=[\"seed\", wkt[\"wandb.group\"]]).apply(\n",
    "    interpolate_steps, xlim=xlim, n_points=50\n",
    ")\n",
    "\n",
    "# from IPython.display import display\n",
    "# display(df)\n",
    "\n",
    "visibility_order = [\"hidden\", \"concat (all)\", \"concat (non-static)\"]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(4, 4), dpi=300)\n",
    "ax = fig.add_subplot(111)\n",
    "ax = sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df,\n",
    "    x=x_key,\n",
    "    y=y_key,\n",
    "    hue=wkt[\"wandb.group\"],\n",
    "    palette=palette,\n",
    "    errorbar=\"ci\",\n",
    "    lw=2,\n",
    "    hue_order=visibility_order\n",
    ")\n",
    "ax.set_xlabel(\"Step\")\n",
    "ax.set_ylabel(\"Return\")\n",
    "ax.legend(title=\"context visibility\")\n",
    "fig.savefig(fig_fn, bbox_inches=\"tight\", dpi=300)\n",
    "print(fig_fn)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gid, gdf in plot_df.groupby(by=[\"visibility\"]):\n",
    "    print(gid, gdf[\"seed\"].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Combined, differ. by interval size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "fig_fn = figoutdir / f\"{env_name}_differdeltarel.png\"\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=1.35)\n",
    "\n",
    "plot_df = load_plot_df(plot_data_fn=plot_data_fn)\n",
    "palette = get_palette_visibility(plot_df)\n",
    "group_keys = [wandb_key_translator[\"context_sampler.uniform_bounds_rel\"]]\n",
    "\n",
    "grid = sns.FacetGrid(data=plot_df, col=group_keys[0], legend_out=True)\n",
    "grid.map_dataframe(\n",
    "    sns.lineplot,\n",
    "    x=wkt[\"train/global_step\"],\n",
    "    y=wkt[\"eval/return\"],\n",
    "    hue=wkt[\"wandb.group\"],\n",
    "    palette=palette,\n",
    "    errorbar=errorbar,\n",
    ")\n",
    "# xticks = np.linspace(0, round(plot_df[wkt[\"train/global_step\"]].max(), -5), 5) # TODO\n",
    "# grid.set(xticks=xticks)\n",
    "grid.add_legend()\n",
    "grid.tight_layout()\n",
    "\n",
    "grid.figure.savefig(fig_fn, bbox_inches=\"tight\", dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid: Rows: Delta_rel, Cols: Visibility, Hue: CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ast\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=1.25)\n",
    "\n",
    "fig_fn = figoutdir / f\"{env_name}_grid__row_deltarel__col_visibility__hue_cf.png\"\n",
    "\n",
    "plot_df = load_plot_df(plot_data_fn=plot_data_fn)\n",
    "palette = get_palette_visibility(plot_df)\n",
    "\n",
    "row = wkt[\"context_sampler.uniform_bounds_rel\"]\n",
    "col = wkt[\"wandb.group\"]\n",
    "hue = wkt[\"context_sampler.context_feature_names\"]\n",
    "xname = wkt[\"train/global_step\"]\n",
    "yname = wkt[\"eval/return\"]\n",
    "\n",
    "grid = sns.FacetGrid(data=plot_df, row=row, col=col, legend_out=True)\n",
    "grid.map_dataframe(sns.lineplot, x=xname, y=yname, hue=hue, palette=\"colorblind\")\n",
    "grid.add_legend()\n",
    "grid.figure.set_tight_layout(True)\n",
    "grid.figure.savefig(fig_fn, bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid: Col: cf, Hue: Visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "fig_fn = figoutdir / f\"{env_name}_grid_col_cf__hue_visibility.png\"\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=1.35)\n",
    "\n",
    "plot_df = load_plot_df(plot_data_fn=plot_data_fn)\n",
    "plot_df.sort_values(by=wkt[\"context_sampler.context_feature_names\"], inplace=True)\n",
    "palette = get_palette_visibility(plot_df)\n",
    "group_keys = [wandb_key_translator[\"context_sampler.context_feature_names\"]]\n",
    "\n",
    "grid = sns.FacetGrid(data=plot_df, col=group_keys[0], legend_out=True)\n",
    "grid.map_dataframe(\n",
    "    sns.lineplot,\n",
    "    x=wkt[\"train/global_step\"],\n",
    "    y=wkt[\"eval/return\"],\n",
    "    hue=wkt[\"wandb.group\"],\n",
    "    palette=palette,\n",
    "    errorbar=errorbar,\n",
    ")\n",
    "# xticks = np.linspace(0, round(plot_df[wkt[\"train/global_step\"]].max(), -5), 5) # TODO\n",
    "# grid.set(xticks=xticks)\n",
    "grid.add_legend()\n",
    "grid.tight_layout()\n",
    "\n",
    "grid.figure.savefig(fig_fn, bbox_inches=\"tight\", dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Plot Combined, differ. by sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "fig_fn = figoutdir / f\"{env_name}_differsigma.png\"\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=1.35)\n",
    "\n",
    "plot_df = load_plot_df(plot_data_fn=plot_data_fn)\n",
    "if env_name == \"CARLBipedalWalkerEnv\":\n",
    "    errorbar = \"sd\"\n",
    "    plot_df = plot_df[plot_df[wkt[\"train/global_step\"]] < 500050]\n",
    "\n",
    "# plot_df = plot_df[plot_df[wkt[\"wandb.group\"]] == \"hidden\"]\n",
    "palette = get_palette_visibility(plot_df)\n",
    "group_keys = [wandb_key_translator[\"context_sampler.sigma_rel\"]]\n",
    "\n",
    "grid = sns.FacetGrid(data=plot_df, col=group_keys[0], legend_out=True)\n",
    "grid.map_dataframe(\n",
    "    sns.lineplot,\n",
    "    x=wkt[\"train/global_step\"],\n",
    "    y=wkt[\"eval/return\"],\n",
    "    hue=wkt[\"wandb.group\"],\n",
    "    palette=palette,\n",
    "    errorbar=errorbar,\n",
    ")\n",
    "# xticks = np.linspace(0, round(plot_df[wkt[\"train/global_step\"]].max(), -5), 5) # TODO\n",
    "# grid.set(xticks=xticks)\n",
    "grid.add_legend()\n",
    "grid.tight_layout()\n",
    "\n",
    "grid.figure.savefig(fig_fn, bbox_inches=\"tight\", dpi=300)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# if env_name == \"CARLPendulumEnv\":\n",
    "#     ylim = (-600, -180)\n",
    "#     _ = [ax.set_ylim(*ylim) for ax in grid.axes.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_df[wkt[\"train/global_step\"]].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid: Rows: std, Cols: Visibility, Hue: CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ast\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=1.25)\n",
    "\n",
    "plot_df = load_plot_df(plot_data_fn=plot_data_fn)\n",
    "palette = get_palette_visibility(plot_df)\n",
    "\n",
    "row = wkt[\"context_sampler.sigma_rel\"]\n",
    "col = wkt[\"wandb.group\"]\n",
    "hue = wkt[\"context_sampler.context_feature_names\"]\n",
    "xname = wkt[\"train/global_step\"]\n",
    "yname = wkt[\"eval/return\"]\n",
    "\n",
    "grid = sns.FacetGrid(data=plot_df, row=row, col=col, legend_out=True)\n",
    "grid.map_dataframe(sns.lineplot, x=xname, y=yname, hue=hue, palette=\"colorblind\")\n",
    "grid.add_legend()\n",
    "grid.figure.set_tight_layout(True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Plot for each sigma, diff grids by changing cf, hue: visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ast\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=1.25)\n",
    "\n",
    "plot_df = load_plot_df(plot_data_fn=plot_data_fn)\n",
    "palette = get_palette_visibility(plot_df)\n",
    "groups = plot_df.groupby(wkt[\"context_sampler.sigma_rel\"])\n",
    "\n",
    "for group_id, group_df in groups:\n",
    "    group_keys = [wkt[\"context_sampler.context_feature_names\"]]\n",
    "    group_df[wkt[\"context_sampler.context_feature_names\"]] = (\n",
    "        group_df[wkt[\"context_sampler.context_feature_names\"]]\n",
    "        .apply(ast.literal_eval)\n",
    "        .apply(tuple)\n",
    "    )\n",
    "    group_df = group_df.sort_values(\n",
    "        by=[wkt[\"context_sampler.context_feature_names\"]],\n",
    "        key=lambda x: [len(xi) for xi in x],\n",
    "    )\n",
    "    grid = sns.FacetGrid(data=group_df, col=group_keys[0], legend_out=True)\n",
    "    grid.map_dataframe(\n",
    "        sns.lineplot,\n",
    "        x=wkt[\"train/global_step\"],\n",
    "        y=wkt[\"eval/return\"],\n",
    "        hue=wkt[\"wandb.group\"],\n",
    "        palette=palette,\n",
    "        errorbar=errorbar,\n",
    "    )\n",
    "    xticks = np.linspace(0, round(group_df[wkt[\"train/global_step\"]].max(), -5), 5)\n",
    "    grid.set(xticks=xticks)\n",
    "    grid.add_legend(label_order=sorted(group_df[wkt[\"wandb.group\"]].unique()))\n",
    "    grid.figure.suptitle(f\"{wkt['context_sampler.sigma_rel']}={group_id}\")\n",
    "    grid.tight_layout()\n",
    "\n",
    "    fig_fn = figoutdir / f\"{env_name}_differcontextfeatures_{group_id}.png\"\n",
    "    grid.figure.savefig(fig_fn, bbox_inches=\"tight\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig_fn = figoutdir / f\"{env_name}_differcontextfeatures_grid.png\"\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=1.2)\n",
    "\n",
    "plot_df = load_plot_df(plot_data_fn=plot_data_fn)\n",
    "palette = get_palette_visibility(plot_df)\n",
    "group_keys = [\n",
    "    wandb_key_translator[\"context_sampler.context_feature_names\"],\n",
    "    wandb_key_translator[\"context_sampler.sigma_rel\"],\n",
    "]\n",
    "\n",
    "plot_df[wkt[\"context_sampler.context_feature_names\"]] = (\n",
    "    plot_df[wkt[\"context_sampler.context_feature_names\"]]\n",
    "    .apply(ast.literal_eval)\n",
    "    .apply(tuple)\n",
    ")\n",
    "plot_df = plot_df.sort_values(\n",
    "    by=[wkt[\"context_sampler.context_feature_names\"]],\n",
    "    key=lambda x: [len(xi) for xi in x],\n",
    ")\n",
    "\n",
    "grid = sns.FacetGrid(\n",
    "    data=plot_df, col=group_keys[0], row=group_keys[1], legend_out=True\n",
    ")\n",
    "grid.map_dataframe(\n",
    "    sns.lineplot,\n",
    "    x=wkt[\"train/global_step\"],\n",
    "    y=wkt[\"eval/return\"],\n",
    "    hue=wkt[\"wandb.group\"],\n",
    "    palette=palette,\n",
    "    errorbar=errorbar,\n",
    ")\n",
    "xticks = np.linspace(0, round(plot_df[wkt[\"train/global_step\"]].max(), -5), 5)\n",
    "grid.set(xticks=xticks)\n",
    "grid.add_legend(label_order=sorted(group_df[wkt[\"wandb.group\"]].unique()))\n",
    "grid.tight_layout()\n",
    "\n",
    "grid.figure.savefig(fig_fn, bbox_inches=\"tight\", dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig_fn = figoutdir / f\"{env_name}_differcontextfeatures.png\"\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=1.25)\n",
    "\n",
    "plot_df = load_plot_df(plot_data_fn=plot_data_fn)\n",
    "palette = get_palette_visibility(plot_df)\n",
    "group_keys = [wandb_key_translator[\"context_sampler.context_feature_names\"]]\n",
    "\n",
    "plot_df[wkt[\"context_sampler.context_feature_names\"]] = (\n",
    "    plot_df[wkt[\"context_sampler.context_feature_names\"]]\n",
    "    .apply(ast.literal_eval)\n",
    "    .apply(tuple)\n",
    ")\n",
    "plot_df = plot_df.sort_values(\n",
    "    by=[wkt[\"context_sampler.context_feature_names\"]],\n",
    "    key=lambda x: [len(xi) for xi in x],\n",
    ")\n",
    "\n",
    "grid = sns.FacetGrid(data=plot_df, col=group_keys[0], legend_out=True)\n",
    "grid.map_dataframe(\n",
    "    sns.lineplot,\n",
    "    x=wkt[\"train/global_step\"],\n",
    "    y=wkt[\"eval/return\"],\n",
    "    hue=wkt[\"wandb.group\"],\n",
    "    palette=palette,\n",
    "    errorbar=errorbar,\n",
    ")\n",
    "xticks = np.linspace(0, round(plot_df[wkt[\"train/global_step\"]].max(), -5), 5)\n",
    "grid.set(xticks=xticks)\n",
    "grid.add_legend(label_order=sorted(group_df[wkt[\"wandb.group\"]].unique()))\n",
    "grid.tight_layout()\n",
    "\n",
    "grid.figure.savefig(fig_fn, bbox_inches=\"tight\", dpi=300)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# if env_name == \"CARLPendulumEnv\":\n",
    "#     ylim = (-600, -180)\n",
    "#     _ = [ax.set_ylim(*ylim) for ax in grid.axes.flatten()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Plot for each sigma, diff grids by changing cf, hue: visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=1.35)\n",
    "\n",
    "plot_df = load_plot_df(plot_data_fn=plot_data_fn)\n",
    "palette = get_palette_visibility(plot_df)\n",
    "plot_df[wkt[\"context_sampler.context_feature_names\"]] = (\n",
    "    plot_df[wkt[\"context_sampler.context_feature_names\"]]\n",
    "    .apply(ast.literal_eval)\n",
    "    .apply(tuple)\n",
    ")\n",
    "plot_df = plot_df.sort_values(\n",
    "    by=[wkt[\"context_sampler.context_feature_names\"]],\n",
    "    key=lambda x: [len(xi) for xi in x],\n",
    ")\n",
    "groups = plot_df.groupby(wkt[\"context_sampler.context_feature_names\"])\n",
    "\n",
    "for group_id, group_df in groups:\n",
    "    group_keys = [wkt[\"context_sampler.sigma_rel\"]]\n",
    "    grid = sns.FacetGrid(data=group_df, col=group_keys[0], legend_out=True)\n",
    "    grid.map_dataframe(\n",
    "        sns.lineplot,\n",
    "        x=wkt[\"train/global_step\"],\n",
    "        y=wkt[\"eval/return\"],\n",
    "        hue=wkt[\"wandb.group\"],\n",
    "        palette=palette,\n",
    "        errorbar=errorbar,\n",
    "    )\n",
    "    xticks = np.linspace(0, round(plot_df[wkt[\"train/global_step\"]].max(), -5), 5)\n",
    "    grid.set(xticks=xticks)\n",
    "    grid.add_legend(label_order=sorted(group_df[wkt[\"wandb.group\"]].unique()))\n",
    "    grid.figure.suptitle(f\"{wkt['context_sampler.context_feature_names']} = {group_id}\")\n",
    "    grid.tight_layout()\n",
    "\n",
    "    fig_fn = figoutdir / f\"{env_name}_differcontextfeatures_{group_id}.png\"\n",
    "    grid.figure.savefig(fig_fn, bbox_inches=\"tight\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Last Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "plot_df = load_plot_df(plot_data_fn=plot_data_fn, load_final=True)\n",
    "\n",
    "key = wkt[\"wandb.group\"]\n",
    "plot_df = plot_df[\n",
    "    (plot_df[key] == \"hidden\")\n",
    "    | (plot_df[key] == \"cgate_hadamard\")\n",
    "    | (plot_df[key] == \"concat (non-static)\")\n",
    "]\n",
    "\n",
    "printr(np.unique(plot_df[\"visibility\"], return_counts=True))\n",
    "printr(len(plot_df[plot_df[\"visibility\"] == \"cgate_hadamard\"]))\n",
    "\n",
    "ylog = True\n",
    "ylabel = \"$R$\"\n",
    "\n",
    "\n",
    "# Prepare dataset\n",
    "ynameplot = wkt[\"eval/return\"]\n",
    "if ylog:\n",
    "    ylabel = \"$- log(-R)$\"\n",
    "    ynameplot += \"_scaled_log\"\n",
    "    Y = plot_df[wkt[\"eval/return\"]].copy()\n",
    "    Y *= -1\n",
    "    Y = np.log(Y)\n",
    "    Y *= -1\n",
    "    plot_df[ynameplot] = Y\n",
    "\n",
    "# Plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=1.25)\n",
    "palette = get_palette_visibility(plot_df)\n",
    "\n",
    "# Plot aggregated\n",
    "fig_fn = figoutdir / f\"{env_name}_deltarel_boxenplot.png\"\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax = sns.boxenplot(\n",
    "    data=plot_df,\n",
    "    x=wkt[\"train/global_step\"],\n",
    "    y=ynameplot,\n",
    "    hue=wkt[\"wandb.group\"],\n",
    "    palette=palette,\n",
    "    showfliers=True,\n",
    ")  # , cut=0)\n",
    "xticklabels = [str(int(round(plot_df[wkt[\"train/global_step\"]].max(), -5)))]\n",
    "# ax.set_xticklabels(xticklabels)\n",
    "ax.set_ylabel(ylabel)\n",
    "fig.set_tight_layout(True)\n",
    "fig.savefig(fig_fn, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Plot per delta rel\n",
    "fig_fn = figoutdir / f\"{env_name}_differdeltarel_boxplot.png\"\n",
    "group_keys = [wandb_key_translator[\"context_sampler.uniform_bounds_rel\"]]\n",
    "\n",
    "row = None\n",
    "col = group_keys[0]\n",
    "\n",
    "grid = sns.FacetGrid(data=plot_df, row=row, col=col, legend_out=True)\n",
    "grid.map_dataframe(\n",
    "    sns.boxplot,\n",
    "    x=wkt[\"train/global_step\"],\n",
    "    y=ynameplot,\n",
    "    hue=wkt[\"wandb.group\"],\n",
    "    palette=palette,\n",
    ")  # , cut=0)\n",
    "grid.add_legend()\n",
    "xticklabels = [str(int(round(plot_df[wkt[\"train/global_step\"]].max(), -5)))]\n",
    "grid.set_xticklabels(xticklabels)\n",
    "grid.set_ylabels(ylabel)\n",
    "grid.tight_layout()\n",
    "grid.figure.savefig(fig_fn, bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot per delta rel, only single variations\n",
    "fig_fn = figoutdir / f\"{env_name}_differdeltarel_boxplot_singlevar.png\"\n",
    "group_keys = [wandb_key_translator[\"context_sampler.uniform_bounds_rel\"]]\n",
    "\n",
    "row = None\n",
    "col = group_keys[0]\n",
    "\n",
    "key = wkt[\"context_sampler.context_feature_names\"]\n",
    "subdf = plot_df[[len(cf) <= 6 for cf in plot_df[key]]]\n",
    "\n",
    "grid = sns.FacetGrid(data=subdf, row=row, col=col, legend_out=True)\n",
    "grid.map_dataframe(\n",
    "    sns.boxplot,\n",
    "    x=wkt[\"train/global_step\"],\n",
    "    y=ynameplot,\n",
    "    hue=wkt[\"wandb.group\"],\n",
    "    palette=palette,\n",
    ")  # , cut=0)\n",
    "grid.add_legend()\n",
    "xticklabels = [str(int(round(plot_df[wkt[\"train/global_step\"]].max(), -5)))]\n",
    "grid.set_xticklabels(xticklabels)\n",
    "grid.set_ylabels(ylabel)\n",
    "grid.tight_layout()\n",
    "grid.figure.savefig(fig_fn, bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot per delta rel, only single variations, no lstm/concat all\n",
    "fig_fn = figoutdir / f\"{env_name}_differdeltarel_boxplot_singlevar_nolstmconcatall.png\"\n",
    "group_keys = [wandb_key_translator[\"context_sampler.uniform_bounds_rel\"]]\n",
    "\n",
    "row = None\n",
    "col = group_keys[0]\n",
    "\n",
    "key = wkt[\"context_sampler.context_feature_names\"]\n",
    "subdf = plot_df[[len(cf) <= 6 for cf in plot_df[key]]]\n",
    "subdf = subdf[\n",
    "    (subdf[wkt[\"wandb.group\"]] != \"cgate_lstm\")\n",
    "    & (subdf[wkt[\"wandb.group\"]] != \"concat (all)\")\n",
    "]\n",
    "\n",
    "grid = sns.FacetGrid(data=subdf, row=row, col=col, legend_out=True)\n",
    "grid.map_dataframe(\n",
    "    sns.boxplot,\n",
    "    x=wkt[\"train/global_step\"],\n",
    "    y=ynameplot,\n",
    "    hue=wkt[\"wandb.group\"],\n",
    "    palette=palette,\n",
    ")  # , cut=0)\n",
    "grid.add_legend()\n",
    "xticklabels = [str(int(round(plot_df[wkt[\"train/global_step\"]].max(), -5)))]\n",
    "grid.set_xticklabels(xticklabels)\n",
    "grid.set_ylabels(ylabel)\n",
    "grid.tight_layout()\n",
    "grid.figure.savefig(fig_fn, bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot per cf, only single variations\n",
    "fig_fn = figoutdir / f\"{env_name}_differdeltarel_boxplot_singlevar_percf.png\"\n",
    "\n",
    "key = wkt[\"context_sampler.context_feature_names\"]\n",
    "subdf = plot_df[[len(cf) <= 6 for cf in plot_df[key]]]\n",
    "\n",
    "row = None\n",
    "col = key\n",
    "showfliers = False\n",
    "\n",
    "grid = sns.FacetGrid(data=subdf, row=row, col=col, legend_out=True)\n",
    "grid.map_dataframe(\n",
    "    sns.boxplot,\n",
    "    x=wkt[\"train/global_step\"],\n",
    "    y=ynameplot,\n",
    "    hue=wkt[\"wandb.group\"],\n",
    "    palette=palette,\n",
    "    showfliers=showfliers,\n",
    ")  # , cut=0)\n",
    "grid.add_legend()\n",
    "xticklabels = [str(int(round(plot_df[wkt[\"train/global_step\"]].max(), -5)))]\n",
    "grid.set_xticklabels(xticklabels)\n",
    "grid.set_ylabels(ylabel)\n",
    "grid.tight_layout()\n",
    "grid.figure.savefig(fig_fn, bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Plot per delta rel and cf\n",
    "fig_fn = figoutdir / f\"{env_name}_differdeltarel_differcf_violinplot.png\"\n",
    "col = group_keys[0]\n",
    "row = wkt[\"context_sampler.context_feature_names\"]\n",
    "group_keys = [wandb_key_translator[\"context_sampler.uniform_bounds_rel\"]]\n",
    "grid = sns.FacetGrid(data=plot_df, row=row, col=col, legend_out=True)\n",
    "grid.map_dataframe(\n",
    "    sns.violinplot,\n",
    "    x=wkt[\"train/global_step\"],\n",
    "    y=ynameplot,\n",
    "    hue=wkt[\"wandb.group\"],\n",
    "    palette=palette,\n",
    "    cut=0,\n",
    ")\n",
    "grid.add_legend()\n",
    "xticklabels = [str(int(round(plot_df[wkt[\"train/global_step\"]].max(), -5)))]\n",
    "# grid.set_xticklabels(xticklabels)\n",
    "grid.set_ylabels(ylabel)\n",
    "grid.tight_layout()\n",
    "grid.figure.savefig(fig_fn, bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot compounding\n",
    "fig_fn = figoutdir / f\"{env_name}_differdeltarel_compounding.png\"\n",
    "col = wkt[\"context_sampler.context_feature_names\"]\n",
    "row = None\n",
    "order = [\n",
    "    \"['m']\",\n",
    "    \"['m', 'l']\",\n",
    "    \"['m', 'l', 'g']\",\n",
    "    \"['m', 'l', 'g', 'dt']\",\n",
    "    \"['m', 'l', 'g', 'dt', 'max_speed']\",\n",
    "]\n",
    "key = wkt[\"context_sampler.context_feature_names\"]\n",
    "subdf = plot_df[[cf in order for cf in plot_df[key]]]\n",
    "subdf = subdf.sort_values(by=key, ascending=False)\n",
    "grid = sns.FacetGrid(data=subdf, row=row, col=col, legend_out=True, row_order=order)\n",
    "grid.map_dataframe(\n",
    "    sns.boxplot,\n",
    "    x=wkt[\"train/global_step\"],\n",
    "    y=ynameplot,\n",
    "    hue=wkt[\"wandb.group\"],\n",
    "    hue_order=list(palette.keys()),\n",
    "    palette=palette,\n",
    ")  # , cut=0)\n",
    "grid.add_legend()\n",
    "xticklabels = [str(int(round(plot_df[wkt[\"train/global_step\"]].max(), -5)))]\n",
    "grid.set_xticklabels(xticklabels)\n",
    "grid.set_ylabels(ylabel)\n",
    "grid.tight_layout()\n",
    "grid.figure.savefig(fig_fn, bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#############################################\n",
    "\n",
    "# # Plot per sigma\n",
    "# fig_fn = figoutdir / f\"{env_name}_differsigma_violinplot.png\"\n",
    "# group_keys = [wandb_key_translator[\"context_sampler.sigma_rel\"]]\n",
    "\n",
    "# row = None\n",
    "# col = group_keys[0]\n",
    "\n",
    "# grid = sns.FacetGrid(data=plot_df, row=row, col=col, legend_out=True)\n",
    "# grid.map_dataframe(sns.boxplot, x=wkt[\"train/global_step\"], y=ynameplot, hue=wkt[\"wandb.group\"], palette=palette)#, cut=0)\n",
    "# grid.add_legend()\n",
    "# xticklabels = [str(int(round(plot_df[wkt[\"train/global_step\"]].max(), -5)))]\n",
    "# grid.set_xticklabels(xticklabels)\n",
    "# grid.set_ylabels(\"$R$\")\n",
    "# grid.tight_layout()\n",
    "# grid.figure.savefig(fig_fn, bbox_inches=\"tight\", dpi=300)\n",
    "# plt.show()\n",
    "\n",
    "# # Plot per sigma and cf\n",
    "# fig_fn = figoutdir / f\"{env_name}_differsigma_differcf_violinplot.png\"\n",
    "# col = group_keys[0]\n",
    "# row = wkt[\"context_sampler.context_feature_names\"]\n",
    "\n",
    "# group_keys = [wandb_key_translator[\"context_sampler.sigma_rel\"]]\n",
    "# grid = sns.FacetGrid(data=plot_df, row=row, col=col, legend_out=True)\n",
    "# grid.map_dataframe(sns.violinplot, x=wkt[\"train/global_step\"], y=ynameplot, hue=wkt[\"wandb.group\"], palette=palette, cut=0)\n",
    "# grid.add_legend()\n",
    "# xticklabels = [str(int(round(plot_df[wkt[\"train/global_step\"]].max(), -5)))]\n",
    "# grid.set_xticklabels(xticklabels)\n",
    "# grid.set_ylabels(\"$R$\")\n",
    "# grid.tight_layout()\n",
    "# grid.figure.savefig(fig_fn, bbox_inches=\"tight\", dpi=300)\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Final Eval (Avg over Seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "\n",
    "plot_df = load_plot_df(plot_data_fn=plot_data_fn, load_final=True)\n",
    "\n",
    "key = wkt[\"wandb.group\"]\n",
    "plot_df = plot_df[\n",
    "    (plot_df[key] == \"hidden\")\n",
    "    | (plot_df[key] == \"cgate_hadamard\")\n",
    "    | (plot_df[key] == \"concat (non-static)\")\n",
    "]\n",
    "\n",
    "reduced = plot_df.groupby(\n",
    "    [wkt[\"wandb.group\"], wkt[\"context_sampler.uniform_bounds_rel\"], \"seed\"]\n",
    ")[wkt[\"eval/return\"]].mean(numeric_only=True)\n",
    "reduced = plot_df.groupby(\n",
    "    [wkt[\"wandb.group\"], wkt[\"context_sampler.uniform_bounds_rel\"], \"seed\"]\n",
    ")[wkt[\"eval/return\"]].apply(scipy.stats.trim_mean, proportiontocut=0.25, axis=None)\n",
    "reduced = reduced.reset_index()  # multi-index (groups) back to normal columns\n",
    "\n",
    "# reduced = plot_df\n",
    "\n",
    "hue = wkt[\"wandb.group\"]\n",
    "x = wkt[\"context_sampler.uniform_bounds_rel\"]\n",
    "y = wkt[\"eval/return\"]\n",
    "ax = sns.violinplot(data=reduced, x=x, y=y, hue=hue, multiple=\"dodge\", cut=0)\n",
    "\n",
    "plt.show()\n",
    "ax = sns.stripplot(data=reduced, x=x, y=y, hue=hue, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdf[wkt[\"wandb.group\"]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdf[key].unique()\n",
    "plot_df[key].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "\n",
    "plot_df = scale(plot_df, yname=wkt[\"eval/return\"], log=False)\n",
    "\n",
    "ynameplot = wkt[\"eval/return\"] + \"_scaled\"\n",
    "\n",
    "# Initialize the FacetGrid object\n",
    "pal = sns.cubehelix_palette(10, rot=-0.25, light=0.7)\n",
    "pal = get_palette_visibility(plot_df)\n",
    "g = sns.FacetGrid(\n",
    "    plot_df,\n",
    "    row=wkt[\"wandb.group\"],\n",
    "    hue=wkt[\"wandb.group\"],\n",
    "    aspect=15,\n",
    "    height=0.5,\n",
    "    palette=pal,\n",
    ")\n",
    "\n",
    "# Draw the densities in a few steps\n",
    "g.map_dataframe(\n",
    "    sns.kdeplot,\n",
    "    x=ynameplot,\n",
    "    bw_adjust=0.5,\n",
    "    clip_on=False,\n",
    "    fill=True,\n",
    "    alpha=1,\n",
    "    linewidth=1.5,\n",
    "    palette=pal,\n",
    ")\n",
    "g.map_dataframe(\n",
    "    sns.kdeplot, x=ynameplot, clip_on=False, color=\"w\", lw=2, bw_adjust=0.5, palette=pal\n",
    ")\n",
    "\n",
    "# passing color=None to refline() uses the hue mapping\n",
    "g.refline(y=0, linewidth=2, linestyle=\"-\", color=None, clip_on=False)\n",
    "\n",
    "\n",
    "# Define and use a simple function to label the plot in axes coordinates\n",
    "# def label(x, color, label):\n",
    "#     ax = plt.gca()\n",
    "#     ax.text(0, .2, label, fontweight=\"bold\", color=color,\n",
    "#             ha=\"left\", va=\"center\", transform=ax.transAxes)\n",
    "# g.map(label, \"x\")\n",
    "\n",
    "visibilities = list(g.axes_dict.keys())\n",
    "for vis, ax in g.axes_dict.items():\n",
    "    color = pal[vis]\n",
    "    label = vis\n",
    "    ax.text(\n",
    "        0,\n",
    "        0.2,\n",
    "        label,\n",
    "        fontweight=\"bold\",\n",
    "        color=color,\n",
    "        ha=\"left\",\n",
    "        va=\"center\",\n",
    "        transform=ax.transAxes,\n",
    "    )\n",
    "\n",
    "print(visibilities)\n",
    "\n",
    "# Set the subplots to overlap\n",
    "g.figure.subplots_adjust(hspace=-0.25)\n",
    "\n",
    "# Remove axes details that don't play well with overlap\n",
    "g.set_titles(\"\")\n",
    "g.set(yticks=[], ylabel=\"\")\n",
    "g.despine(bottom=True, left=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from rliable import library as rly\n",
    "from rliable import metrics\n",
    "from rliable import plot_utils\n",
    "import warnings\n",
    "\n",
    "\n",
    "# Prepare dataset\n",
    "ynameplot = wkt[\"eval/return\"]  # + \"_scaled_log\"\n",
    "\n",
    "# Plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=1.25)\n",
    "\n",
    "\n",
    "# Plot aggregated\n",
    "def plot_aggregated_boxenplot(\n",
    "    plot_df: pd.DataFrame,\n",
    "    env_name: str,\n",
    "    figoutdir: Path,\n",
    "    yname: str,\n",
    "    palette=None,\n",
    "):\n",
    "    if palette is None:\n",
    "        palette = get_palette_visibility(plot_df)\n",
    "    fig_fn = figoutdir / f\"{env_name}_boxenplot.png\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax = sns.boxenplot(\n",
    "        data=plot_df,\n",
    "        x=wkt[\"train/global_step\"],\n",
    "        y=yname,\n",
    "        hue=wkt[\"wandb.group\"],\n",
    "        palette=palette,\n",
    "        showfliers=True,\n",
    "    )  # , cut=0)\n",
    "    # ax = sns.violinplot(data=plot_df, x=wkt[\"train/global_step\"], y=yname, hue=wkt[\"wandb.group\"], palette=palette, cut=0)\n",
    "    xticklabels = [str(int(round(plot_df[wkt[\"train/global_step\"]].max(), -5)))]\n",
    "    ax.set_xticklabels(xticklabels)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    fig.set_tight_layout(True)\n",
    "    fig.savefig(fig_fn, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "metric_names = [\"Median\", \"IQM\", \"Mean\", \"Optimality Gap\"]\n",
    "aggregate_func = lambda x: np.array(\n",
    "    [\n",
    "        metrics.aggregate_median(x),\n",
    "        metrics.aggregate_iqm(x),\n",
    "        metrics.aggregate_mean(x),\n",
    "        metrics.aggregate_optimality_gap(x),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "reps = 5000  # 50000\n",
    "\n",
    "\n",
    "env_names = [\n",
    "    # \"CARLPendulumEnv\",\n",
    "    \"CARLAcrobotEnv\",\n",
    "    \"CARLDmcWalkerEnv\",\n",
    "    \"CARLDmcQuadrupedEnv\",\n",
    "    \"CARLMountainCarEnv\",\n",
    "]\n",
    "\n",
    "for env_name in env_names:\n",
    "    print(env_name)\n",
    "    eval_data_fn = get_eval_data_fn(outdir=outdir, env_name=env_name)\n",
    "    plot_data_fn = get_plot_data_fn(eval_data_fn=eval_data_fn)\n",
    "    plot_df = load_plot_df(plot_data_fn=plot_data_fn, load_final=True)\n",
    "    plot_df = plot_df[plot_df[wkt[\"context_sampler.sigma_rel\"]] == 0.5]\n",
    "    plot_df = plot_df[\n",
    "        (plot_df[wkt[\"wandb.group\"]] == \"concat (all)\")\n",
    "        | (plot_df[wkt[\"wandb.group\"]] == \"hidden\")\n",
    "    ]\n",
    "\n",
    "    score_dict = {}\n",
    "    for group_id, group_df in plot_df.groupby(\"visibility\"):\n",
    "        wide = group_df[[wkt[\"eval/return\"], wkt[\"seed\"]]]\n",
    "        # seeds are ordered\n",
    "        n_seeds = wide[\"seed\"].nunique()\n",
    "        # we want shape (n_tasks, n_seeds)\n",
    "        # print(wide.to_numpy().shape)\n",
    "        # print(wide.to_numpy().flatten().reshape(n_seeds, -1))\n",
    "\n",
    "        # we want (n_seeds, n_tasks)\n",
    "        n_tasks = 6\n",
    "        scores = []\n",
    "        for gid, gdf in group_df.groupby(\"seed\"):\n",
    "            print(gid, len(gdf))\n",
    "            S = gdf[wkt[\"eval/return\"]].to_numpy()\n",
    "            if len(S) < n_tasks:\n",
    "                warnings.warn(\"Imputing missing task evals with nan\")\n",
    "                n_impute = n_tasks - len(S)\n",
    "                impute = [np.nan] * n_impute\n",
    "                S = np.array(list(S) + impute)\n",
    "            scores.append(S)\n",
    "        scores = np.array(scores).T\n",
    "        print(group_id, scores.shape)\n",
    "\n",
    "        scores = gdf[wkt[\"eval/return\"]].to_numpy().reshape(1, -1)\n",
    "\n",
    "        score_dict[group_id] = scores\n",
    "\n",
    "    aggregate_scores, aggregate_score_cis = rly.get_interval_estimates(\n",
    "        score_dict, aggregate_func, reps=reps\n",
    "    )\n",
    "\n",
    "    plot_aggregated_boxenplot(\n",
    "        plot_df=plot_df, env_name=env_name, figoutdir=figoutdir, yname=ynameplot\n",
    "    )\n",
    "\n",
    "    fig, axes = plot_utils.plot_interval_estimates(\n",
    "        aggregate_scores,\n",
    "        aggregate_score_cis,\n",
    "        metric_names=metric_names,\n",
    "        algorithms=algorithms,\n",
    "        xlabel=wkt[\"eval/return\"],\n",
    "    )\n",
    "    # fig.set_tight_layout(True)\n",
    "    plt.show()\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(round(plot_df[\"$k$\"].unique().mean(), -5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('carl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true,
  "vscode": {
   "interpreter": {
    "hash": "445f316a49a09d784fc20e9b3e621eb4aa26f31c3cfbe2b15408208fc87e667a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
