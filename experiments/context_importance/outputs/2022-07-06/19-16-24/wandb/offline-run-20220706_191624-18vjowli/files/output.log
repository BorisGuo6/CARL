context_args
[1m[[32m[22m'gravity'[39m[1m]
[2022-07-06 19:16:29,787][absl][INFO] - Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker:
[2022-07-06 19:16:29,788][absl][INFO] - Unable to initialize backend 'gpu': NOT_FOUND: Could not find registered platform with name: "cuda". Available platform names are: Interpreter Host
[2022-07-06 19:16:29,788][absl][INFO] - Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.
[2022-07-06 19:16:29,788][absl][WARNING] - No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
Error executing job with overrides: ['+environment=cartpole.yaml']
Traceback (most recent call last):
  File "/home/mohan/git/current_projects/contextual_rl/attention/CARL/experiments/context_importance/run_context_importance.py", line 210, in main
    performance_default = tae_runner(configuration_space.get_default_configuration(), file_id="default")
  File "/home/mohan/git/current_projects/contextual_rl/attention/CARL/experiments/context_importance/run_context_importance.py", line 166, in eval_agent
    avg_return = sac(cfg, env, eval_env)
  File "/home/mohan/git/current_projects/contextual_rl/attention/CARL/experiments/context_gating/algorithms/sac.py", line 18, in sac
    pi = coax.Policy(func_pi, env, random_seed=cfg.seed)
  File "/home/mohan/miniconda3/envs/attention-context/lib/python3.9/site-packages/coax/_core/policy.py", line 51, in __init__
    super().__init__(
  File "/home/mohan/miniconda3/envs/attention-context/lib/python3.9/site-packages/coax/_core/base_stochastic_func_type2.py", line 132, in __init__
    super().__init__(
  File "/home/mohan/miniconda3/envs/attention-context/lib/python3.9/site-packages/coax/_core/base_func.py", line 80, in __init__
    self._params, self._function_state = transformed.init(self.rng, *example_data.inputs.args)
  File "/home/mohan/miniconda3/envs/attention-context/lib/python3.9/site-packages/haiku/_src/transform.py", line 364, in init_fn
    f(*args, **kwargs)
  File "/home/mohan/git/current_projects/contextual_rl/attention/CARL/experiments/context_gating/networks/sac.py", line 36, in pi
    x = pi_seq(x)
  File "/home/mohan/miniconda3/envs/attention-context/lib/python3.9/site-packages/haiku/_src/module.py", line 428, in wrapped
    out = f(*args, **kwargs)
  File "/home/mohan/miniconda3/envs/attention-context/lib/python3.9/site-packages/haiku/_src/module.py", line 279, in run_interceptors
    return bound_method(*args, **kwargs)
  File "/home/mohan/miniconda3/envs/attention-context/lib/python3.9/site-packages/haiku/_src/basic.py", line 127, in __call__
    out = layer(out)
  File "/home/mohan/miniconda3/envs/attention-context/lib/python3.9/site-packages/haiku/_src/module.py", line 428, in wrapped
    out = f(*args, **kwargs)
  File "/home/mohan/miniconda3/envs/attention-context/lib/python3.9/site-packages/haiku/_src/module.py", line 279, in run_interceptors
    return bound_method(*args, **kwargs)
  File "/home/mohan/miniconda3/envs/attention-context/lib/python3.9/site-packages/haiku/_src/basic.py", line 178, in __call__
    w = hk.get_parameter("w", [input_size, output_size], dtype, init=w_init)
  File "/home/mohan/miniconda3/envs/attention-context/lib/python3.9/site-packages/haiku/_src/base.py", line 311, in get_parameter
    param = run_creators(param_creator_stack, context, shape, dtype, init)
  File "/home/mohan/miniconda3/envs/attention-context/lib/python3.9/site-packages/haiku/_src/base.py", line 370, in run_creators
    return init(shape, dtype)
  File "/home/mohan/miniconda3/envs/attention-context/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py", line 3665, in zeros
    return lax.full(shape, 0, dtype)
  File "/home/mohan/miniconda3/envs/attention-context/lib/python3.9/site-packages/jax/_src/lax/lax.py", line 1721, in full
    shape = canonicalize_shape(shape)
  File "/home/mohan/miniconda3/envs/attention-context/lib/python3.9/site-packages/jax/core.py", line 1458, in canonicalize_shape
    raise _invalid_shape_error(shape, context)
TypeError: Shapes must be 1D sequences of concrete values of integer type, got [32, 2.0].
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.